{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wrtVZF7B43X"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "Ps-xXGqcB7mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (28, 28, 1)\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_train=x_train / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "x_test=x_test/255.0\n"
      ],
      "metadata": {
        "id": "uFTsQLwpB8-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.argsort(y_train)\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]"
      ],
      "metadata": {
        "id": "TYnyPXdXB_Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx1= np.argsort(y_test)\n",
        "x_test = x_test[idx1]\n",
        "y_test = y_test[idx1]"
      ],
      "metadata": {
        "id": "-XlCWgwYCBDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "list1=[]\n",
        "for j in range(10):\n",
        "  list1.append(count)\n",
        "  for i in y_train:\n",
        "    if i == j:\n",
        "      count = count+1\n",
        "  print(count)"
      ],
      "metadata": {
        "id": "FrKGYt1lCDII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "list2=[]\n",
        "for j in range(10):\n",
        "  list2.append(count)\n",
        "  for i in y_test:\n",
        "    if i == j:\n",
        "      count = count+1\n",
        "  print(count)"
      ],
      "metadata": {
        "id": "iz78owg_CEpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1.append(60000)\n",
        "list2.append(10000)"
      ],
      "metadata": {
        "id": "wO1-4au8CGFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iid_data_x = []\n",
        "iid_data_y = []\n",
        "for i in range(10):\n",
        "  iid_data_x.append(x_train[list1[i]:list1[i+1]])\n",
        "  iid_data_y.append(y_train[list1[i]:list1[i+1]])"
      ],
      "metadata": {
        "id": "dKAEEcwNCIJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "mixin_ratio = 0.5\n",
        "clients = []\n",
        "y_train = []\n",
        "for i in range(10):\n",
        "  empty = np.zeros((6000,28,28,1))\n",
        "  num_samp = int(6000*mixin_ratio)\n",
        "  samp_1 = i\n",
        "  samp_2 = (i+1)%10\n",
        "  y_temp= np.zeros((6000))\n",
        "  y_temp[:num_samp] = samp_1\n",
        "  y_temp[num_samp:] = samp_2\n",
        "  y_temp = list(y_temp)\n",
        "  \n",
        "  y_train = y_train + y_temp\n",
        "  \n",
        "  empty[:num_samp] = iid_data_x[samp_1][:(num_samp)]\n",
        "  empty[num_samp:] = iid_data_x[samp_2][:(6000-num_samp)]\n",
        "\n",
        "  clients.append(empty)"
      ],
      "metadata": {
        "id": "j8LgiuJ5CKBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "3niPhKdMCSD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 2\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "pC9S9Z77CSFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((7, 7, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "nPBfsrlwCSJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "c2fFSB9iCgim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_list = []\n",
        "history_list = []\n",
        "autoencoder_list = []\n",
        "encoded_images_train = []\n",
        "decoded_images_train = []\n",
        "encoded_images_test = []\n",
        "decoded_images_test = []\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  latent_dim = 2\n",
        "\n",
        "  encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "  x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "  x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(16, activation=\"relu\")(x)\n",
        "  z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "  z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "  z = Sampling()([z_mean, z_log_var])\n",
        "  encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "  encoder.summary()\n",
        "\n",
        "  latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "  x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
        "  x = layers.Reshape((7, 7, 64))(x)\n",
        "  x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "  x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "  decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "  decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "  decoder.summary()\n",
        "\n",
        "  autoencoder_list.append(VAE(encoder, decoder)) \n",
        "  autoencoder_list[i].compile(optimizer=tf.keras.optimizers.Adam())\n",
        "  autoencoder_list[i].fit(iid_data_x[i], epochs=30, batch_size = 16)\n",
        "  \n",
        "  # n = 10\n",
        "  # plt.figure(figsize=(20, 4))\n",
        "  # for j in range(n):\n",
        "  #   # display original\n",
        "  #   ax = plt.subplot(2, n, j + 1)\n",
        "  #   plt.imshow(iid_data_x[i][j,:,:,0])\n",
        "  #   plt.title(\"original\")\n",
        "  #   plt.gray()\n",
        "  #   ax.get_xaxis().set_visible(False)\n",
        "  #   ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  #   # display reconstruction\n",
        "  #   ax = plt.subplot(2, n, j + 1 + n)\n",
        "  #   plt.imshow(encoded_images_train[i].reshape(encoded_images_train[i].shape[0],8,8,1)[j,:,:,0])\n",
        "  #   plt.title(\"reconstructed\")\n",
        "  #   plt.gray()\n",
        "  #   ax.get_xaxis().set_visible(False)\n",
        "  #   ax.get_yaxis().set_visible(False)\n",
        "  # plt.show()"
      ],
      "metadata": {
        "id": "iub5SVXED9Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # (x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "# # # mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "# # # mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
        "\n",
        "# vae = VAE(encoder, decoder)\n",
        "# vae.compile(optimizer=keras.optimizers.Adam())\n",
        "# vae.fit(iid_data_x[2], epochs=2, batch_size=128)"
      ],
      "metadata": {
        "id": "GqRN6wLFCpym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_encoded_train = []\n",
        "digit_size = 28\n",
        "scale = 1\n",
        "# figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# linearly spaced coordinates corresponding to the 2D plot\n",
        "# of digit classes in the latent space\n",
        "for r in range(10):\n",
        "  print(r)\n",
        "  grid_x = np.linspace(-scale, scale, 70)\n",
        "  grid_y = np.linspace(-scale, scale, 70)[::-1]\n",
        "  for i, yi in enumerate(grid_y):\n",
        "      for j, xi in enumerate(grid_x):\n",
        "          z_sample = np.array([[xi, yi]])\n",
        "          x_decoded = autoencoder_list[r].decoder.predict(z_sample).reshape(28,28,1)\n",
        "          overall_encoded_train.append(x_decoded)\n",
        "        # print(x_decoded.shape)\n",
        "        # n = 10\n",
        "        # plt.figure()\n",
        "        # plt.imshow(x_decoded[:,:,0])\n",
        "        # plt.title(\"original\")\n",
        "        # plt.gray()\n",
        "        # plt.get_xaxis().set_visible(False)\n",
        "        # plt.get_yaxis().set_visible(False)\n",
        "        # plt.show()\n",
        "\n",
        "        # digit = x_decoded[0].reshape(digit_size, digit_size)"
      ],
      "metadata": {
        "id": "Y4OLxeuJC93e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_new = np.zeros((49000))\n",
        "for i in range(10):\n",
        "  for j in range(4900):\n",
        "    y_train_new[i*4900+j] = i"
      ],
      "metadata": {
        "id": "ZnctsH3BFzRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_new = np.array(overall_encoded_train)"
      ],
      "metadata": {
        "id": "6ybEkf3NM-c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_new.shape"
      ],
      "metadata": {
        "id": "6vLrBgoeOsVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (5,5), padding='same', activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.Conv2D(32, (5,5), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Dropout(0.7),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.7),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "8wHMwTnUNpU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "overall_encoded_train, y_train = shuffle(x_train_new,y_train_new, random_state=7)"
      ],
      "metadata": {
        "id": "mfMmdzlrNsPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_new = tf.one_hot(y_train_new.astype(np.int32), depth=10)\n",
        "y_test = tf.one_hot(y_test.astype(np.int32), depth=10)"
      ],
      "metadata": {
        "id": "-kNZ_W1rN1qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(x_train_new, y_train_new,\n",
        "                    batch_size=16,\n",
        "                    epochs=1)"
      ],
      "metadata": {
        "id": "Fi7dqF5vN3Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model2.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "GAP9tiBEOBDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for j in range(n):\n",
        "  # display original\n",
        "  ax = plt.subplot(2, n, j + 1)\n",
        "  plt.imshow(x_train_new[j+4900*8,:,:,0])\n",
        "  plt.title(\"new\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # # display reconstruction\n",
        "  # ax = plt.subplot(2, n, j + 1 + n)\n",
        "  # plt.imshow(encoded_images_train[i].reshape(encoded_images_train[i].shape[0],8,8,1)[j,:,:,0])\n",
        "  # plt.title(\"reconstructed\")\n",
        "  # plt.gray()\n",
        "  # ax.get_xaxis().set_visible(False)\n",
        "  # ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5WI2C8FhWQae"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}