{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prquCrkSrFNQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_estEsZ1rGhK",
        "outputId": "9a4cd34d-b49c-4b88-fb9d-b76d030ada74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (28, 28, 1)\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_train=x_train / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "x_test=x_test/255.0"
      ],
      "metadata": {
        "id": "IBurhOXSrIOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.argsort(y_train)\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]"
      ],
      "metadata": {
        "id": "8HdvSgFRrUev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx1= np.argsort(y_test)\n",
        "x_test = x_test[idx1]\n",
        "y_test = y_test[idx1]"
      ],
      "metadata": {
        "id": "g0uVnFmwaqJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCRsPWDObCEV",
        "outputId": "00cf6b12-0a4b-4554-f24e-c1412656bfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "list1=[]\n",
        "for j in range(10):\n",
        "  list1.append(count)\n",
        "  for i in y_train:\n",
        "    if i == j:\n",
        "      count = count+1\n",
        "  print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZgY5FtctE4K",
        "outputId": "b2ae2ca3-e58a-4254-9cca-75b8243c80bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5923\n",
            "12665\n",
            "18623\n",
            "24754\n",
            "30596\n",
            "36017\n",
            "41935\n",
            "48200\n",
            "54051\n",
            "60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "list2=[]\n",
        "for j in range(10):\n",
        "  list2.append(count)\n",
        "  for i in y_test:\n",
        "    if i == j:\n",
        "      count = count+1\n",
        "  print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyTOS74ra0ZU",
        "outputId": "efddf309-782e-43e8-d6dd-c00289d0cf43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "980\n",
            "2115\n",
            "3147\n",
            "4157\n",
            "5139\n",
            "6031\n",
            "6989\n",
            "8017\n",
            "8991\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list1.append(60000)\n",
        "list2.append(10000)"
      ],
      "metadata": {
        "id": "_aiIq-XhTunC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNtfjBT6SoiL",
        "outputId": "ee7a96e1-c09c-44c1-8179-feb7c135487f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 5923, 12665, 18623, 24754, 30596, 36017, 41935, 48200, 54051, 60000]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
        "y_test = tf.one_hot(y_test.astype(np.int32), depth=10)"
      ],
      "metadata": {
        "id": "vwzky0EJrN2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iid_data_x = []\n",
        "iid_data_y = []\n",
        "for i in range(10):\n",
        "  iid_data_x.append(x_train[list1[i]:list1[i+1]])\n",
        "  iid_data_y.append(y_train[list1[i]:list1[i+1]])"
      ],
      "metadata": {
        "id": "bWvpylVtSKfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iid_data_x.append(iid_data_x[0])"
      ],
      "metadata": {
        "id": "4XQYO8dQ8HRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "mixin_ratio = 0.9\n",
        "clients = []\n",
        "y_train = []\n",
        "for i in range(10):\n",
        "  empty = np.zeros((6000,28,28,1))\n",
        "  num_samp = int(6000*mixin_ratio)\n",
        "  samp_1 = i\n",
        "  samp_2 = (i+1)%10\n",
        "  y_temp= np.zeros((6000))\n",
        "  y_temp[:num_samp] = samp_1\n",
        "  y_temp[num_samp:] = samp_2\n",
        "  y_temp = list(y_temp)\n",
        "  \n",
        "  y_train = y_train + y_temp\n",
        "  \n",
        "  empty[:num_samp] = iid_data_x[samp_1][:(num_samp)]\n",
        "  empty[num_samp:] = iid_data_x[samp_2][:(6000-num_samp)]\n",
        "\n",
        "  clients.append(empty)"
      ],
      "metadata": {
        "id": "XHK-aYNwBNIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "\n",
        "# mixin_ratio = 0.5\n",
        "# clients = []\n",
        "# y_train = []\n",
        "# for i in range(10):\n",
        "#   empty = np.zeros((6000,28,28,1))\n",
        "#   num_samp = int(6000*mixin_ratio)\n",
        "#   samp_1 = random.randint(0, 9)\n",
        "#   samp_2 = random.randint(0, 9)\n",
        "#   y_temp= np.zeros((6000))\n",
        "#   y_temp[:num_samp] = samp_1\n",
        "#   y_temp[:(6000-num_samp)] = samp_2\n",
        "#   y_temp = list(y_temp)\n",
        "  \n",
        "#   y_train = y_train + y_temp\n",
        "  \n",
        "#   empty[:num_samp] = iid_data_x[samp_1][:(num_samp)]\n",
        "#   empty[:(6000-num_samp)] = iid_data_x[samp_2][:(6000-num_samp)]\n",
        "\n",
        "#   clients.append(empty)"
      ],
      "metadata": {
        "id": "f3ZxT5JI6eR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(np.array(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePNsTsY1Ac7R",
        "outputId": "c45f4d6a-14f5-4a64-dd33-4ce7ec257e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = tf.one_hot(np.array(y_train).astype(np.int32), depth=10)"
      ],
      "metadata": {
        "id": "u9bKPu6iB7yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 64 \n",
        "\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.latent_dim = latent_dim   \n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(784, activation='sigmoid'),\n",
        "      layers.Reshape((28,28,1))\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "  \n",
        "autoencoder = Autoencoder(latent_dim) "
      ],
      "metadata": {
        "id": "mybbtKi2tJr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_list = []\n",
        "history_list = []\n",
        "autoencoder_list = []\n",
        "encoded_images_train = []\n",
        "decoded_images_train = []\n",
        "encoded_images_test = []\n",
        "decoded_images_test = []\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  autoencoder_list.append(Autoencoder(latent_dim)) \n",
        "  autoencoder_list[i].compile(optimizer=tf.keras.optimizers.Adam(), loss=losses.MeanSquaredError(),metrics=['acc'])\n",
        "\n",
        "  autoencoder_list[i].fit(clients[i],clients[i],\n",
        "                epochs=10)\n",
        "  \n",
        "  encoded_images_train.append(autoencoder_list[i].encoder(clients[i]).numpy())\n",
        "\n",
        "  n = 10\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  for j in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, j + 1)\n",
        "    plt.imshow(clients[i][j,:,:,0])\n",
        "    plt.title(\"original\")\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, j + 1 + n)\n",
        "    plt.imshow(encoded_images_train[i].reshape(encoded_images_train[i].shape[0],8,8,1)[j,:,:,0])\n",
        "    plt.title(\"reconstructed\")\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qciByaMgT-Dg",
        "outputId": "7707c197-5176-4578-ef88-e0f9f9667537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 4s 4ms/step - loss: 0.0592 - acc: 0.7412\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0281 - acc: 0.7675\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0201 - acc: 0.7717\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0158 - acc: 0.7735\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0132 - acc: 0.7746\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0115 - acc: 0.7753\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0101 - acc: 0.7757\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0091 - acc: 0.7760\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0083 - acc: 0.7762\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0076 - acc: 0.7764\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0441 - acc: 0.8617\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0157 - acc: 0.8803\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.0118 - acc: 0.8820\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0095 - acc: 0.8828\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0079 - acc: 0.8834\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0068 - acc: 0.8838\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0060 - acc: 0.8841\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0053 - acc: 0.8843\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0048 - acc: 0.8844\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0044 - acc: 0.8846\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0666 - acc: 0.7570\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0333 - acc: 0.7820\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0250 - acc: 0.7860\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0203 - acc: 0.7883\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0172 - acc: 0.7895\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0150 - acc: 0.7904\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0132 - acc: 0.7909\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0118 - acc: 0.7914\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0105 - acc: 0.7917\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0095 - acc: 0.7920\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0627 - acc: 0.7671\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0318 - acc: 0.7904\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.0237 - acc: 0.7946\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0190 - acc: 0.7968\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.0161 - acc: 0.7979\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0139 - acc: 0.7987\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0122 - acc: 0.7993\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0108 - acc: 0.7997\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.0096 - acc: 0.8000\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0087 - acc: 0.8003\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0598 - acc: 0.7962\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0280 - acc: 0.8162\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0215 - acc: 0.8189\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0180 - acc: 0.8203\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0153 - acc: 0.8213\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0133 - acc: 0.8221\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0117 - acc: 0.8226\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0104 - acc: 0.8230\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0093 - acc: 0.8234\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0084 - acc: 0.8236\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0638 - acc: 0.7789\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0318 - acc: 0.8009\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.0241 - acc: 0.8049\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0195 - acc: 0.8071\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0164 - acc: 0.8084\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0141 - acc: 0.8092\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0123 - acc: 0.8098\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0109 - acc: 0.8103\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0097 - acc: 0.8106\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0087 - acc: 0.8108\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0587 - acc: 0.7764\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0268 - acc: 0.8006\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0202 - acc: 0.8040\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0162 - acc: 0.8059\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0137 - acc: 0.8068\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0119 - acc: 0.8075\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0105 - acc: 0.8079\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0094 - acc: 0.8083\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0085 - acc: 0.8085\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0077 - acc: 0.8088\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0556 - acc: 0.8057\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0256 - acc: 0.8258\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0200 - acc: 0.8282\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0164 - acc: 0.8297\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0138 - acc: 0.8307\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0118 - acc: 0.8314\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0103 - acc: 0.8320\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0091 - acc: 0.8323\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0081 - acc: 0.8326\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0073 - acc: 0.8328\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0621 - acc: 0.7551\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0335 - acc: 0.7774\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0254 - acc: 0.7821\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0205 - acc: 0.7846\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0172 - acc: 0.7861\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0148 - acc: 0.7870\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0130 - acc: 0.7877\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0115 - acc: 0.7881\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0104 - acc: 0.7885\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0094 - acc: 0.7887\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0579 - acc: 0.7872\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0259 - acc: 0.8090\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0194 - acc: 0.8123\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0157 - acc: 0.8141\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0130 - acc: 0.8152\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.0112 - acc: 0.8159\n",
            "Epoch 7/10\n",
            "  1/188 [..............................] - ETA: 1s - loss: 0.0098 - acc: 0.8195"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-46b8f5456244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   autoencoder_list[i].fit(clients[i],clients[i],\n\u001b[0;32m---> 15\u001b[0;31m                 epochs=10)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mencoded_images_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_encoded_train = np.zeros((60000,latent_dim))\n",
        "\n",
        "for i in range(10):\n",
        "  overall_encoded_train[i*6000:(i+1)*6000] = encoded_images_train[i]\n",
        "\n",
        "overall_encoded_train = overall_encoded_train.reshape((overall_encoded_train.shape[0], 8, 8, 1))"
      ],
      "metadata": {
        "id": "p4dp-a2qC-OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overall_encoded_train = np.zeros((60000,latent_dim))\n",
        "\n",
        "# for i in range(10):\n",
        "#   overall_encoded_train[int(list1[i]):int(list1[i+1])] = encoded_images_train[i]\n",
        "\n",
        "# overall_encoded_train = overall_encoded_train.reshape((overall_encoded_train.shape[0], 8, 8, 1))"
      ],
      "metadata": {
        "id": "jgcpacy8UdoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (5,5), padding='same', activation='relu', input_shape=(8,8,1)),\n",
        "    tf.keras.layers.Conv2D(32, (5,5), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Dropout(0.6),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "DrjavjOUVfUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(overall_encoded_train.shape)"
      ],
      "metadata": {
        "id": "ydHaTi7vXNJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(overall_encoded_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=10)"
      ],
      "metadata": {
        "id": "H-2MJbA0VmnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overall_encoded_test = np.zeros((10000,8,8,1))\n",
        "# for i in range(10):\n",
        "#   overall_encoded_test[list2[i]:list2[i+1]]= autoencoder_list[i].encoder(x_test[list2[i]:list2[i+1]]).numpy().reshape(x_test[list2[i]:list2[i+1]].shape[0],8,8,1)"
      ],
      "metadata": {
        "id": "UGWeGBGzbKSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_encoded_test = np.zeros((10000,8,8,1))\n",
        "for i in range(10):\n",
        "  overall_encoded_test[list2[i]:list2[i+1]]= autoencoder_list[i].encoder(x_test[list2[i]:list2[i+1]]).numpy().reshape(x_test[list2[i]:list2[i+1]].shape[0],8,8,1)"
      ],
      "metadata": {
        "id": "Se7gAwHYDWK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model2.evaluate(overall_encoded_test, y_test)"
      ],
      "metadata": {
        "id": "LUNt-U4IacwN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}